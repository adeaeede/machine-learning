{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "\n",
    "    def classify(self, X, k):\n",
    "        def classify_single(x):\n",
    "            distances = np.sqrt(np.sum(np.square(self._train_x - x), axis=1))\n",
    "            nearest_labels = self._train_y[np.argpartition(distances, k)[:k]]\n",
    "            predicted = np.argmax(np.bincount(nearest_labels))\n",
    "            return predicted\n",
    "        if X.ndim == 1:\n",
    "            return classify_single(X)\n",
    "        elif X.ndim == 2:\n",
    "            y_pred = np.empty(len(X), dtype=np.uint8)\n",
    "            for i in range(len(X)):\n",
    "                y_pred[i] = classify_single(X[i])\n",
    "            return y_pred\n",
    "        else:\n",
    "            raise ValueError('invalid input shape')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _training_data = np.array(pd.read_csv('zip.train', sep=' ', header=None),\n",
    "                              dtype=np.float32)\n",
    "    _test_data = np.array(pd.read_csv('zip.test', sep=' ', header=None),\n",
    "                          dtype=np.float32)\n",
    "\n",
    "    _train_x = _training_data[:, 1:-1]\n",
    "    _train_y = _training_data[:, 0].astype(np.uint8)\n",
    "\n",
    "    _test_x = _test_data[:, 1:]\n",
    "    _test_y = _test_data[:, 0].astype(np.uint8)\n",
    "\n",
    "    for k in range(1, 16):\n",
    "        _n_test_samples = 2007\n",
    "        _knn = KNNClassifier(_train_x, _train_y)\n",
    "        _y_pred = _knn.classify(_test_x[:_n_test_samples], k)\n",
    "        _accuracy = np.sum(np.equal(_y_pred, _test_y[:_n_test_samples])) / len(_y_pred)\n",
    "        _true_neg = _test_x[:_n_test_samples][np.where(np.not_equal(_y_pred, _test_y[:_n_test_samples]))]\n",
    "        _conf_m = pd.crosstab(pd.Series(_test_y[:_n_test_samples], name='Actual'),\n",
    "                              pd.Series(_y_pred, name='Predicted'))        \n",
    "        plt.imshow(_true_neg[np.random.randint(0,_true_neg.shape[0])].reshape(16,16), cmap='gray')\n",
    "        print('k', k)\n",
    "        print('Accuracy', _accuracy)\n",
    "        print(_conf_m)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beste Ergebnisse wurden mit dem Werten k=3 und k=5 erreicht.\n",
    "\n",
    "Vorteile des kNN Classifiers\n",
    "    - Einfach zum Implementieren\n",
    "    - Keine Trainigsphase\n",
    "Nachteile des kNN Classifiers\n",
    "    - Kurze trainingsphase dafür aber lange testphase\n",
    "    - Das testen verbraucht sehr viele Resourcen\n",
    "    - Ungenau bei höheren Dimensionen, wegen kleinen Unterschied der Abstände der jeweiligen Datenpunkte\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
